{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52d4b0f-1a91-4f9a-a8aa-5511c676861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain_community langchain_chroma langchainhub pypdf langchain-ollama langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6970796-38a5-4d79-9712-fc8bededb093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shubhamrathod/PycharmProjects/RAG_Pipeline/RAG_Chain\n",
      "/Users/shubhamrathod/PycharmProjects/RAG_Pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "\n",
    "ROOT = os.path.dirname(HOME)\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46efcf4-f4ed-4b5c-b8ca-9b96a1e01f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fca4119-eeb9-4423-8d3f-769d7d8a261e",
   "metadata": {},
   "source": [
    "# Load the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698189a5-e746-47c5-9b7f-8dfdbf090681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = f'{HOME}/CC.pdf'\n",
    "loader = PyPDFLoader(file_path = file_path)\n",
    "\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d1d460-dda3-4641-9893-a7d6fbe3012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116c8a3-460a-4ab8-825a-5aa9237cd08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b4fa0-14c9-4288-89d4-8ec551a047ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c8c34ee-d0ce-4d24-a51e-a169ff42646d",
   "metadata": {},
   "source": [
    "# Split the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c668e09-611e-41ef-a63b-26f1c46007f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676b3970-50d4-4444-8661-804a2400a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=8000,\n",
    "    chunk_overlap=3000,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224d76af-09df-4048-81d6-2e590f6415c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1756b51-c97c-4d11-9ee8-10e2a8166c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2506eeb-56d5-4376-9dd3-87d7a5a39a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54235ccc-8c4a-4106-94ab-3d21606daf2b",
   "metadata": {},
   "source": [
    "# Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a1ad28-ce38-40b9-b7be-6a8a603fd201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c848de2-2266-4311-9a27-c1ca07622d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e806f894-a450-4809-a6f8-7754a2c8a1f7",
   "metadata": {},
   "source": [
    "# Create Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6cced5-dda9-431f-bfb0-a07cba0227ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334eb334-8f3a-41e7-b78b-9ba3f983cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = f'{HOME}/chroma_db'\n",
    "\n",
    "if os.path.isdir(persist_directory):\n",
    "    # Load from disk.\n",
    "    index = Chroma(persist_directory = persist_directory, embedding_function = embeddings)\n",
    "else:\n",
    "    # Save to disk.  \n",
    "    index = Chroma.from_documents(documents = docs, embedding = embeddings, persist_directory = persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae14af0-ed80-40ae-ac8d-5cc3fbc18bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 1, 'source': '/Users/shubhamrathod/PycharmProjects/RAG_Pipeline/RAG_Chain/CC.pdf'}, page_content='the bill that you received was generated a week before you made the \\npayment that’s why your latest payment had not been reflected. You can \\nsimply disregard the amount indicated  in the bill and continue enjoying \\nour servic es. \\nCustomer:     Thank you.  \\nAgent:           Delays in the bill is usually caused by delays in our courier services. \\nFor a more up dated bill of your account, you can visit our website and \\nlog in to your account. This bill is more updated.  \\nCustomer:     O k I will.'), Document(metadata={'page': 3, 'source': '/Users/shubhamrathod/PycharmProjects/RAG_Pipeline/RAG_Chain/CC.pdf'}, page_content='the documents from and deliver the sim to you. May I know the convenient time \\nwhen you would be Available?  \\n \\nCustomer:  Ok, send your executive at 11 am tomorrow.  \\n \\nAgent:  Ok, sir. Thank you very mu ch. Have a nice day.  \\n \\nCustomer:  You’re welcome. You too have a nice day. Bye.  \\n \\nAgent:  bye.'), Document(metadata={'page': 1, 'source': '/Users/shubhamrathod/PycharmProjects/RAG_Pipeline/RAG_Chain/CC.pdf'}, page_content='Customer:     Maegan Simpson, July 23, 1974 and the account is under my name.  \\nAgent:            Thank you for that information mam. Per our system’s data, you did \\npay your last bill last Aug. 12 which was two days ago in one of our \\naffiliated payment centers and you c urrently have 0 balance. However, \\nthe bill that you received was generated a week before you made the \\npayment that’s why your latest payment had not been reflected. You can'), Document(metadata={'page': 0, 'source': '/Users/shubhamrathod/PycharmProjects/RAG_Pipeline/RAG_Chain/CC.pdf'}, page_content=\"Customer:  I would like to know  my remaining money in my account.  \\nAgent:  I'll be glad to help you. May I please get your Bank Account number and the Name \\non the Account?  \\nCustomer:  Sure, it's Tracy  Q. Randall, account number is 805 -7845 -3895 -061 \\nAgent:  Thank you, let me just check on it. Ok, can you please, verify the last four numbers \\nof your social security ID?  \\nCustomer:  It is ****.  \\nAgent:  You still have 84 thousand and 65 cents. Is there anything  else that I could assist\")]\n"
     ]
    }
   ],
   "source": [
    "docs = index.similarity_search('Who is emily')\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f010fa1-0195-4e56-9a64-c8700cd4c299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff122c5-d7f3-4fa7-9253-365ba8b040aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d3ae801-b3fb-46b3-9699-91f34e1a2ed2",
   "metadata": {},
   "source": [
    "# Create Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f82ced3-d122-43e3-bb14-56700e74e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52f234-c163-4063-8af2-fd0acbfc609e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926d140-c774-407d-9cd3-61b1bc829250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b8d0806-7935-455e-9e81-9088ae6a7f01",
   "metadata": {},
   "source": [
    "# History Aware Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9de55f2f-0717-4319-8095-404fcb090e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8f9ef11-4f9a-4c9a-bc15-613ff830e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6f91220-dce2-4aa5-a958-96e46058ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = (\n",
    "    \"\"\"Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "014ca472-7ad0-4585-ae9f-6f3990ac6507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualize_q_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c72364c-7092-45e0-8b10-9229d9a9093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e1bb756-8c0f-4c7a-bea9-bf911b44b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8fae7-f1ec-4107-a9c4-22aa99504dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98944077-dc57-43ae-af5e-bcbb74873664",
   "metadata": {},
   "source": [
    "# Prompt - Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22ac910a-0b2c-422a-8ba0-41723a43cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "\n",
    "    You are an assistant for question-answering tasks. Your Name is PLN, Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    \n",
    "    Context: {context} \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20ce7fcd-257a-4f82-8d97-f074ee2bd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10888ed5-a76c-43f5-a915-95eb03fbd759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44e8fb-8fca-4764-9597-723eeb1c9d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6f06b55-0e8f-4c0b-b6c0-2e7c4a07d5f5",
   "metadata": {},
   "source": [
    "# Run Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39524afc-0acb-4d6c-9fa6-786ceabc15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b021624-dd4a-4e2e-8ee8-deb89b0676f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f43df265-7d1f-462a-bcb9-459fc7164795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"Which Bank did Tracy go to?\"\n",
    "# ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "\n",
    "# chat_history.extend(\n",
    "#     [\n",
    "#         HumanMessage(content=question),\n",
    "#         AIMessage(content=ai_msg_1[\"answer\"]),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(ai_msg_1['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd851d8d-407b-4919-bc6e-6b7f224c0b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "011d7509-4494-486a-97e2-014156f851dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b55b5d8e-e63e-47db-bcb7-6429fe881960",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5192b453-a1e5-4b25-8e96-823b54cd14f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('answer')\n",
      "Error in callback coroutine: KeyError('answer')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know. The context only mentions a customer named John Perez, not Tracy, and it's about ordering pizza from Pizza Loco, not going to a bank.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Which Bank did Tracy go to?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318df80d-0b4a-4171-b61a-d92940835d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myrag",
   "language": "python",
   "name": "myrag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
