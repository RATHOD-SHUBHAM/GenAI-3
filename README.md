# GenAI-3
This repository is my platform to learn, experiment, and innovate with LLMs. Here I try to dive in and discover diverse applications, research experiments, and projects fueled by the power of language models.

---

## Content

1] Langchain Expression Language.
2] Advance RAG:
  i] Hybrid RAG.
  ii] ReRanking.
  iii] Graph RAG.
3] Agents.

---

## Projects

1] 🌟 PCBinsightAI: Your New PCB Defect Detective 🌟



I’ve been working on something cool: PCBinsightAI! 🚀 Leveraging a powerhouse of advanced technologies, including YOLOv10 for object detection, SAM for segmentation, and OpenAI's Language Model (LLM) for intelligent chat capabilities, PCBinsightAI brings unparalleled precision to identifying and understanding defects in printed circuit boards.



🔍 Object Detection with YOLOv10: PCBinsightAI utilizes the state-of-the-art YOLOv10 model to accurately identify defects in uploaded PCB images. With its high precision and speed, YOLOv10 forms the backbone of the defect detection pipeline.



🖼️ Segmentation with SAM: Following object detection, SAM (Segmentation-Aware Modules) steps in to provide precise segmentation of detected defects. This ensures that each defect is precisely outlined, enabling comprehensive analysis and understanding.



💬 Intelligent Chat with OpenAI LLM: PCBinsightAI doesn't stop there! With the integration of OpenAI's Language Model, users can now engage in insightful conversations about detected defects. Whether it's understanding the root causes of damage or exploring precautionary measures, the LLM-powered chat feature is here to provide valuable insights and guidance.



🔢 Cutting-Edge Techniques: Behind the scenes, PCBinsightAI harnesses advanced techniques such as RAG (Retrieval-Augmented Generation) and VectorDB (Pinecone) for enhanced performance and efficiency. By employing innovative methods like embedding models and semantic search, PCBinsightAI ensures a fast and accurate responses.



🌐💡Here's how it works:

 * Upload: Simply upload an image of your PCB.

 * Object Detection: Powerful YOLOv10 model scans the image and identifies any defects.

 * Segmentation: The SAM model steps in to segment these defects with pinpoint accuracy.

 * Interactive Chat: With OpenAI’s LLM, you can ask questions about the defects, learn their causes, and get advice on prevention and remedies.



🌟 Why is this important? 

Imagine the impact on:

 - 🏭 Manufacturing: Streamlining quality control on production lines.

- 🔍 Quality Assurance: Quickly identifying and analyzing defects to maintain high standards.

- 🔬R&D: Providing insights into common defect patterns during the design and testing phases.

- 🔋Maintenance: Helping technicians diagnose and address PCB issues efficiently.

---

<img width="1410" alt="ss_1" src="https://github.com/RATHOD-SHUBHAM/GenAI-3/assets/58945964/5d1a4c4f-7e5e-4a95-b8e8-ee824920f914">

---

<img width="2271" alt="SS" src="https://github.com/RATHOD-SHUBHAM/GenAI-3/assets/58945964/61d84e5f-1ed2-486e-aec3-3a8740eb857d">

---

<img width="2207" alt="ss_2" src="https://github.com/RATHOD-SHUBHAM/GenAI-3/assets/58945964/ce6731a6-1e96-451f-81ea-d572f4631428">

---

# EchoAI 🎙️✨
Welcome to EchoAI, the next-generation voice-driven AI that listens, understands, and fulfills your requests—all powered by advanced generative AI technologies.

# Overview
EchoAI is designed to take your voice commands and transform them into actions seamlessly. Whether it's setting a reminder, fetching information, or controlling smart devices, EchoAI has you covered. 
This app leverages state-of-the-art AI frameworks and tools to deliver an intuitive and efficient user experience.

# Key Features
  * Voice-Activated Commands: Trigger EchoAI using a custom wake word and speak your request naturally.
  * Automated Speech Recognition (ASR): Powered by OpenAI's Whisper, ensuring accurate voice-to-text conversion.
  * Text-to-Speech (TTS): EchoAI responds in a clear, natural voice, making interaction smooth and engaging.
  * Intelligent Agents: Agents powered by OpenAI's Language Model (LLM) analyze your requests and choose the best tools from a versatile toolkit to fulfill them.
  * Multi-Tool Support: EchoAI’s agents have access to a wide array of tools, ensuring the right solution for every request.
  * Langchain Framework: The backbone of EchoAI, providing a robust and scalable structure for managing complex voice interactions.

# Technology Stack
  * Langchain Framework: For handling complex interactions and integrating various components seamlessly.
  * Porcupine: Used for the wake word detection, making sure EchoAI is always ready to listen.
  * Whisper (OpenAI): For precise and reliable speech recognition.
  * OpenAI LLM: Powers the intelligent agents that process commands and fulfill requests.
  * Text-to-Speech (TTS): Converts the response back to spoken language.

# Getting Started
## Prerequisites
  1. Python 3.10 or later
  2. Required Python packages (listed in requirements.txt)

## Installation
Clone this repository:
```
  $git clone https://github.com/yourusername/myToothless.git
  $cd myToothless
```

## Install the required dependencies:

```
  $pip install -r requirements.txt
```

## Set up your environment variables for OpenAI API keys, Porcupine access keys, etc.
Run the application:
```
  $python main.py
```

# Usage
Once the application is running, Toothless will be in a listening state. Use your designated wake word to activate Toothless and start giving commands.

WakeWord
```
  Toothless
```
---

